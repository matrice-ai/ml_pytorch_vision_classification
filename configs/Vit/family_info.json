{
    "modelFamily": "ViT",
    "modelInputs": "image",
    "modelOutputs": "classification",
    "models": [
        {
            "modelKey": "vit_b_16",
            "modelName": "ViT-B/16"
        },
        {
            "modelKey": "vit_b_32",
            "modelName": "ViT-B/32"
        },
        {
            "modelKey": "vit_h_14",
            "modelName": "ViT-H/14"
        },
        {
            "modelKey": "vit_l_16",
            "modelName": "ViT-L/16"
        },
        {
            "modelKey": "vit_l_32",
            "modelName": "ViT-L/32"
        }
    ],
    "description": "Vision Transformer (ViT) is a transformer-based deep neural network architecture\n                    designed for image classification. It processes images in a tokenized manner,\n                    treating them as sequences of patches. ViT has achieved state-of-the-art results\n                    in various computer vision tasks.",
    "trainingFramework": "PyTorch",
    "supportedRuntimes": [
        "PyTorch",
        "TensorFlow",
        "ONNX",
        "OpenVINO"
    ],
    "benchmarkDatasets": [
        "ImageNet"
    ],
    "supportedMetrics": [
        "acc@1",
        "acc@5",
        "f1_score",
        "recall",
        "precision",
        "specificity"
    ],
    "pruningSupport": false,
    "codeRepository": "https://github.com/google-research/vision_transformer",
    "trainingDockerContainer": [
        "pytorch/pytorch"
    ],
    "dataProcessing": {
        "inputFormat": "ImageNet",
        "dataLoaderClassDefinition": "null",
        "dataLoaderCallSignature": "DataLoader(source_path, dest_path, **kwargs)"
    },
    "references": [
        "https://arxiv.org/abs/2010.11929"
    ],
    "isPrivate": false,
    "projectId": ""
}